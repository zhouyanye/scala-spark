# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# ??RollingFileAppender??????????
log4j.appender.rolling=org.apache.log4j.RollingFileAppender
log4j.appender.rolling.File=./spark.log
log4j.appender.rolling.MaxFileSize=10MB
log4j.appender.rolling.MaxBackupIndex=5
log4j.appender.rolling.layout=org.apache.log4j.PatternLayout
log4j.appender.rolling.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

# ???RollingFileAppender???root logger
# Set everything to be logged to the console
log4j.rootCategory=WARN, console, rolling
log4j.appender.console=org.apache.log4j.ConsoleAppender
log4j.appender.console.target=System.err
log4j.appender.console.layout=org.apache.log4j.PatternLayout
log4j.appender.console.layout.ConversionPattern=%d{yy/MM/dd HH:mm:ss} %p %c{1}: %m%n

log4j.logger.org.apache.spark.repl.SparkILoop=INFO
log4j.logger.org.apache.spark.repl.SparkILoopInit=WARN
log4j.logger.org.apache.spark.repl.SparkILoopInit$=WARN
# Set the default spark-shell/spark-sql log level to WARN. When running the
# spark-shell/spark-sql, the log level for these classes is used to overwrite
# the root logger's log level, so that the user can have different defaults
# for the shell and regular Spark apps.
log4j.logger.org.apache.spark.repl.Main=WARN
log4j.logger.org.apache.spark.repl.Main$=WARN
log4j.logger.org.apache.spark.sql.hive.thriftserver.SparkSQLCLIDriver=WARN


# Settings to quiet third party logs that are too verbose
log4j.logger.org.sparkproject.jetty=WARN
log4j.logger.org.sparkproject.jetty.server.HttpChannel=ERROR
log4j.logger.org.sparkproject.jetty.server.HttpConnection=ERROR
log4j.logger.org.sparkproject.jetty.util.component.AbstractLifeCycle=ERROR
log4j.logger.org.apache.spark.repl.SparkIMain$exprTyper=INFO
log4j.logger.org.apache.spark.repl.SparkILoop$SparkILoopInterpreter=INFO
log4j.logger.org.apache.parquet=ERROR
log4j.logger.parquet=ERROR
log4j.logger.org.apache.zookeeper=ERROR
log4j.logger.org.apache.zookeeper.server.NIOServerCnxn=ERROR
log4j.logger.org.apache.zookeeper.server.NIOServerCnxnFactory=ERROR
log4j.logger.org.apache.zookeeper.server.quorum.Learner=ERROR
log4j.logger.org.apache.zookeeper.server.quorum.QuorumPeer=ERROR
log4j.logger.org.apache.zookeeper.server.quorum.QuorumPeerConfig=ERROR
kafka.root.logger.level=WARN
log4j.logger.org.apache.kafka=WARN
log4j.logger.org.apache.kafka.clients.consumer.ConsumerConfig=ERROR
log4j.logger.org.apache.kafka.clients.producer.internals.Metadata=ERROR
log4j.logger.org.apache.kafka.clients.consumer.internals.Fetcher=ERROR
log4j.logger.org.apache.kafka.common.metrics.KafkaMetric=ERROR
log4j.logger.org.apache.kafka.common.utils.AppInfoParser=ERROR
log4j.logger.org.apache.kafka.common.utils.KafkaThread=ERROR
mysql.log.level=WARN
mysql.root.log.level=WARN
log4j.logger.org.apache.spark.sql.hive.thriftserver.HiveThriftServer2=WARN
log4j.logger.org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$=WARN
log4j.logger.org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$ThriftServer2Handler=ERROR
log4j.logger.org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$TServerEventHandler=ERROR
log4j.logger.org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$TThreadPoolServer=WARN
log4j.logger.org.apache.spark.sql.hive.thriftserver.HiveThriftServer2$TThreadPoolServer$WorkerProcess=WARN


# SPARK-9183: Settings to avoid annoying messages when looking up nonexistent UDFs in SparkSQL with Hive support
log4j.logger.org.apache.hadoop.hive.metastore.RetryingHMSHandler=FATAL
log4j.logger.org.apache.hadoop.hive.ql.exec.FunctionRegistry=ERROR

# For deploying Spark ThriftServer
# SPARK-34128?Suppress undesirable TTransportException warnings involved in THRIFT-4805
log4j.appender.console.filter.1=org.apache.log4j.varia.StringMatchFilter
log4j.appender.console.filter.1.StringToMatch=Thrift error occurred during processing of message
log4j.appender.console.filter.1.AcceptOnMatch=false
log4j.appender.console.filter.2=org.apache.log4j.varia.StringMatchFilter
log4j.appender.console.filter.2.StringToMatch=Error in deserializing return row for function
log4j.appender.console.filter.2.AcceptOnMatch=false
